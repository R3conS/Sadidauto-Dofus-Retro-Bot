import cv2 as cv
import numpy as np
import threading
from window_capture import Window_Capture
from threading_tools import Threading_Tools


class Detection:


    # Constants.
    GAMEWINDOW_DEFAULT_REGION = (0, 30, 935, 725)
    GAMEWINDOW_OFFSET_X = GAMEWINDOW_DEFAULT_REGION[0]
    GAMEWINDOW_OFFSET_Y = GAMEWINDOW_DEFAULT_REGION[1]


    # Properties.
    opencv_match_method = None
    needle_img = None
    needle_w = 0
    needle_h = 0
    

    # Constructor.
    def __init__(self, opencv_match_method=cv.TM_CCOEFF_NORMED):

        # Loading the match method that cv_matchTemplate will be using (there are several to choose from in OpenCV docs).
        # Default method will be: cv.TM_CCOEFF_NORMED.
        self.opencv_match_method = opencv_match_method


    # Finds a 'needle' image on a 'haystack' image. Must be provided the paths to the images as strings.
    # Will also work if the images are pre-converted to 'numpy.ndarray'.
    def find(self, haystack_img, needle_img, threshold=0.6):

        # Converting the 'haystack_img' to a 'numpy.ndarray'.
        if not isinstance(haystack_img, np.ndarray):
            haystack_img = cv.imread(haystack_img, cv.IMREAD_UNCHANGED)

        # Converting the 'haystack_img' to a 'numpy.ndarray'.
        if not isinstance(needle_img, np.ndarray):
            needle_img = cv.imread(needle_img, cv.IMREAD_UNCHANGED)

        # Using matchTemplate to find 'needle_img' in 'haystack_img'.
        result = cv.matchTemplate(haystack_img, needle_img, self.opencv_match_method)

        # Finding best matches (using threshold) and getting the (x, y) coordinates of those matches.
        locations = np.where(result >= threshold)
        locations = list(zip(*locations[::-1]))

        # Creating a list of rectangles that stores information of the found matches (x, y, w, h).
        # The list is later used in 'cv.groupRectangles()'.
        rectangles = []
        for loc in locations:
            rect = [int(loc[0]), int(loc[1]), needle_img.shape[1], needle_img.shape[0]]
            # Appending to the list twice because 'cv.groupRectangles()' requires at least two overlapping rectangles for it group
            # them together. If only appending once, 'cv.groupRectangles()' will throw out any results (even if they're correct)
            # that do not overlap.
            rectangles.append(rect)
            rectangles.append(rect)

        # Grouping all rectangles that are close by.
        rectangles, weights = cv.groupRectangles(rectangles, 1, 0.5)

        return rectangles


    # Calculates center (x, y) coordinates of found objects from provided 'rectangles' dimensions (x, y, w, h).
    # The 'rectangles' dimensions are generated by the 'find()' method.
    def get_click_points(self, rectangles):

        points = []

        for (x, y, w, h) in rectangles:
            
            # Determining the center positions of found matches.
            center_x = x + int(w/2)
            center_y = y + int(h/2)
            # Saving the center positions.
            points.append((center_x, center_y))

        return points


    # These offset coordinates are used when script needs to click on found 'needle' images.
    # It converts the (x, y) coordinates found on the 'haystack' image to clickable coordinates on screen.
    def get_offset_click_points(self, coordinates):

        return (coordinates[0] + self.GAMEWINDOW_OFFSET_X, coordinates[1] + self.GAMEWINDOW_OFFSET_Y)


    # Draws a box around found objects using (x, y, w, h) coordinates provided by 'find()' method.
    # 'rectangles' must be a list of lists, or list of tuples.
    def draw_rectangles(self, haystack_img, rectangles):

        line_color = (0, 255, 0)
        line_type = cv.LINE_4

        for (x, y, w, h) in rectangles:
            # Determining the box positions.
            top_left = (x, y)
            bottom_right = (x + w, y + h)
            # Draw the box/rectangle.
            cv.rectangle(haystack_img, top_left, bottom_right, line_color, line_type)

        return haystack_img


    # Draws markers on center (x, y) coordinates of found objects. 'Points' can be generated by 'get_click_points' method.
    def draw_crosshairs(self, haystack_img, points):

        marker_color = (255, 0, 255)
        marker_type = (cv.MARKER_CROSS)

        for (center_x, center_y) in points:
            # Drawing markers on the center positions of found matches.
            cv.drawMarker(haystack_img, (center_x, center_y), marker_color, marker_type)

        return haystack_img


    # Detects provided objects on a 'haystack image' (provided by Window_Capture()). Doesn't work when there's only 1 'image' in the 'images_list'.
    # Must be at least 2. Can be the same 'image' string copied twice. Doesn't work very well though. This method is best used when trying to detect
    # multiple (>10) 'images'. Like detecting monsters for example. If accurate results for 1 'image' are needed, then it's best to use another method.
    def detect_objects(self, images_list, images_folder_path, threshold=0.6, capture_region_coordinates=GAMEWINDOW_DEFAULT_REGION):

        # Getting an updated screenshot (haystack) of the game.
        screenshot = Window_Capture().gamewindow_capture(capture_region=capture_region_coordinates)

        # Looping over all needle images and trying to find them on the haystack image (screenshot).
        # Appending all information of found matches to an empty list.
        # This generates a list of 2D numpy arrays.
        object_rectangles = []
        for image in images_list:
            rectangles = self.find(screenshot, images_folder_path + image, threshold)
            object_rectangles.append(rectangles)

        # Converting a list of 2D numpy arrays into a list of 1D numpy arrays.
        object_rectangles_converted = []
        for i in object_rectangles:
            for j in i:
                object_rectangles_converted.append(j)

        # Converting a list of 1D numpy arrays into one 2D numpy array.
        object_rectangles_converted = np.array(object_rectangles_converted)

        # Grouping all rectangles that are close-by to reduce amount of matches.
        object_rectangles_converted, weights = cv.groupRectangles(object_rectangles_converted, 1, 0.5)

        # Creating a list containing center (x, y) coordinates of found matches.
        object_center_xy_coordinates = self.get_click_points(object_rectangles_converted)

        return object_rectangles_converted, object_center_xy_coordinates


#--------------------------------------------------------------------------------------------------------------------


class Object_Detection(Detection):


    # Threading properties.
    Object_Detection_Thread_stopped = True
    Object_Detection_Thread_lock = None
    Object_Detection_Thread_thread = None


    # Properties.
    screenshot = None
    threshold = None
    object_images = []
    object_images_folder_path = []
    rectangles = []
    click_points = []


    def __init__(self, object_images, object_images_folder_path, threshold=0.6, opencv_match_method=cv.TM_CCOEFF_NORMED):

        # Inheriting from parent class.
        super().__init__(opencv_match_method=cv.TM_CCOEFF_NORMED)

        # Loading images to look for and their paths.
        self.object_images = object_images
        self.object_images_folder_path = object_images_folder_path

        # Loading detection threshold (0.6 by default)
        self.threshold = threshold

        # Initializing a 'threading.Lock()' object.
        self.Object_Detection_Thread_lock = threading.Lock()

        # Initializing a 'Threading_Tools()' object.
        self.threading_tools = Threading_Tools()


    def update(self, screenshot):

        self.Object_Detection_Thread_lock.acquire()
        self.screenshot = screenshot
        self.Object_Detection_Thread_lock.release()


    def Object_Detection_Thread_start(self):

        self.Object_Detection_Thread_stopped = False
        self.Object_Detection_Thread_thread = threading.Thread(target=self.Object_Detection_Thread_run)
        self.Object_Detection_Thread_thread.start()
        self.threading_tools.wait_for_thread_to_start(self.Object_Detection_Thread_thread)
        

    def Object_Detection_Thread_stop(self):

        self.Object_Detection_Thread_stopped = True
        self.threading_tools.wait_for_thread_to_stop(self.Object_Detection_Thread_thread)


    def Object_Detection_Thread_run(self):

        while not self.Object_Detection_Thread_stopped:
            if self.screenshot is not None:
                # Do object detection.
                rectangles, click_points = self.detect_objects(self.object_images, self.object_images_folder_path, self.threshold)
                # Lock the thread while updating results.
                self.Object_Detection_Thread_lock.acquire()
                self.rectangles = rectangles
                self.click_points = click_points
                self.Object_Detection_Thread_lock.release()
